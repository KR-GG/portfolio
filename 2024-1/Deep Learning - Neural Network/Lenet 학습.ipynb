{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cde0c3",
   "metadata": {},
   "source": [
    "# 오늘은 LeNet 구조를 만들어봅시다\n",
    "\n",
    "\n",
    "LeNet 구조는 CNN이며, 초기에 만들어진 모델입니다. \n",
    "\n",
    "2가지 모델(Sigmoid, ReLU)를 만들어 두 모델의 성능을 비교해봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aff3fd",
   "metadata": {},
   "source": [
    "## 1.우선 필요 라이브러리를 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd17ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bac6b",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.13.1+cpu  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5590af",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 \n",
    "\n",
    " 1. Training data와 Test data 분리하기\n",
    " \n",
    " 2. Training data를 Training data 와 Validation data로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00908077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "train, val = torch.utils.data.random_split(train_data, [int(0.8 * len(train_data)), int(0.2 * len(train_data))])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ffb80",
   "metadata": {},
   "source": [
    "## 4. torch.nn을 이용하여 모델-1 만들기\n",
    "\n",
    "   1) 아래의 그림 중 LeNet 구조를 구현 할 것\n",
    "   \n",
    "   2) Sigmoid 활성화 함수를 이용할 것\n",
    "   \n",
    "   \n",
    "![](Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defacffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26eed9",
   "metadata": {},
   "source": [
    "## 5. torch.nn을 이용하여 모델-2 만들기\n",
    "\n",
    "   LeNet 모델에서 ReLU 활성화 함수를 사용하시요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ac70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de556825",
   "metadata": {},
   "source": [
    "## 7. 학습 준비하기\n",
    "\n",
    "1) 1 epoch를 학습할 수 있는 함수 만들기\n",
    "\n",
    "2) Test와 Validation data의 정확도 계산할 수 있는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06030b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(train_loader, network, loss_func, optimizer, epoch):\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "    log_interval = 300\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # 미분값의 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagration 계산하기.\n",
    "        outputs = network.forward(image)\n",
    "        \n",
    "        \n",
    "        # Cross_entropy 함수를 적용하여 loss를 구하고 저장하기\n",
    "        loss = loss_func(outputs, label)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # training accuracy 정확도 구하기 위해 맞는 샘플 개수 세기\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        train_correct += pred.eq(label).sum()\n",
    "\n",
    "        # Gradinet 구하기\n",
    "        loss.backward()\n",
    "\n",
    "        # weight값 update 하기\n",
    "        optimizer.step()\n",
    "\n",
    "        # 학습 상황 출력\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batch_idx * len(label), len(train_loader.dataset),100. * batch_idx / len(train_loader),\n",
    "                          loss.item()))\n",
    "            \n",
    "    return train_losses, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c0dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_loader, network, loss_func, val = False):\n",
    "    correct = 0\n",
    "    \n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # Forward propagration 계산하기.\n",
    "            outputs = network.forward(image)\n",
    "\n",
    "            # Cross_entropy 함수를 적용하여 loss를 구하기\n",
    "            loss = loss_func(outputs, label)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Batch 별로 정확도 구하기\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            correct += pred.eq(label).sum()\n",
    "\n",
    "        # 전체 정확도 구하기\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        #중간결과 출력\n",
    "        if val is True:\n",
    "                print('Validation set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        else:\n",
    "            print('Test set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "                  .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "    return test_losses, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d73c53",
   "metadata": {},
   "source": [
    "## 8. 위 정의된 함수로 학습 함수 만들기\n",
    "\n",
    "Adam Optimizer를 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df29783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(network, learning_rate = 0.001):\n",
    "    \n",
    "    epoches = 15\n",
    "    \n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr = learning_rate)\n",
    "    \n",
    "    train_losses_per_epoch = []\n",
    "    test_losses_per_epoch = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "                \n",
    "        # 모델를 학습 중이라고 선언하기\n",
    "        network.train()\n",
    "        \n",
    "        train_losses, train_correct = training_epoch(train_loader,network,cls_loss,optimizer, epoch)\n",
    "        \n",
    "        # epoch 별로 loss 평균값, 정확도 구하기\n",
    "        average_loss = np.mean(train_losses)\n",
    "        train_losses_per_epoch.append(average_loss)\n",
    "        \n",
    "        train_accuracy = train_correct / len(train_loader.dataset) * 100\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # epoch 별로 정확도 출력\n",
    "        print('\\nTraining set: Accuracy: {}/{} ({:.2f}%)'\n",
    "              .format(train_correct, len(train_loader.dataset),100. * train_correct / len(train_loader.dataset)))\n",
    "\n",
    "        \n",
    "        ### 학습 중에 test 결과 보기\n",
    "        \n",
    "        # 모델 test 중인 것을 선언하기\n",
    "        network.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            test_losses, test_accuracy = test_epoch(val_loader, network, cls_loss, True)\n",
    "\n",
    "        test_losses_per_epoch.append(np.mean(test_losses))\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_losses, test_accuracy = test_epoch(test_loader, network, cls_loss, False)\n",
    "        \n",
    "    return train_losses_per_epoch, test_losses_per_epoch, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1394321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/48000 (0.00%)]\tLoss: 2.304011\n",
      "Train Epoch: 0 [19200/48000 (40.00%)]\tLoss: 0.845138\n",
      "Train Epoch: 0 [38400/48000 (80.00%)]\tLoss: 0.631324\n",
      "\n",
      "Training set: Accuracy: 32162/48000 (67.00%)\n",
      "Validation set: Accuracy: 10937/12000 (91.14%)\n",
      "\n",
      "Train Epoch: 1 [0/48000 (0.00%)]\tLoss: 0.348825\n",
      "Train Epoch: 1 [19200/48000 (40.00%)]\tLoss: 0.340111\n",
      "Train Epoch: 1 [38400/48000 (80.00%)]\tLoss: 0.201641\n",
      "\n",
      "Training set: Accuracy: 44485/48000 (92.68%)\n",
      "Validation set: Accuracy: 11238/12000 (93.65%)\n",
      "\n",
      "Train Epoch: 2 [0/48000 (0.00%)]\tLoss: 0.185105\n",
      "Train Epoch: 2 [19200/48000 (40.00%)]\tLoss: 0.146570\n",
      "Train Epoch: 2 [38400/48000 (80.00%)]\tLoss: 0.049101\n",
      "\n",
      "Training set: Accuracy: 45624/48000 (95.05%)\n",
      "Validation set: Accuracy: 11522/12000 (96.02%)\n",
      "\n",
      "Train Epoch: 3 [0/48000 (0.00%)]\tLoss: 0.158597\n",
      "Train Epoch: 3 [19200/48000 (40.00%)]\tLoss: 0.241910\n",
      "Train Epoch: 3 [38400/48000 (80.00%)]\tLoss: 0.127208\n",
      "\n",
      "Training set: Accuracy: 46139/48000 (96.12%)\n",
      "Validation set: Accuracy: 11599/12000 (96.66%)\n",
      "\n",
      "Train Epoch: 4 [0/48000 (0.00%)]\tLoss: 0.175331\n",
      "Train Epoch: 4 [19200/48000 (40.00%)]\tLoss: 0.160639\n",
      "Train Epoch: 4 [38400/48000 (80.00%)]\tLoss: 0.140499\n",
      "\n",
      "Training set: Accuracy: 46520/48000 (96.92%)\n",
      "Validation set: Accuracy: 11653/12000 (97.11%)\n",
      "\n",
      "Train Epoch: 5 [0/48000 (0.00%)]\tLoss: 0.048682\n",
      "Train Epoch: 5 [19200/48000 (40.00%)]\tLoss: 0.101872\n",
      "Train Epoch: 5 [38400/48000 (80.00%)]\tLoss: 0.071054\n",
      "\n",
      "Training set: Accuracy: 46740/48000 (97.38%)\n",
      "Validation set: Accuracy: 11698/12000 (97.48%)\n",
      "\n",
      "Train Epoch: 6 [0/48000 (0.00%)]\tLoss: 0.118579\n",
      "Train Epoch: 6 [19200/48000 (40.00%)]\tLoss: 0.233445\n",
      "Train Epoch: 6 [38400/48000 (80.00%)]\tLoss: 0.041949\n",
      "\n",
      "Training set: Accuracy: 46861/48000 (97.63%)\n",
      "Validation set: Accuracy: 11700/12000 (97.50%)\n",
      "\n",
      "Train Epoch: 7 [0/48000 (0.00%)]\tLoss: 0.098164\n",
      "Train Epoch: 7 [19200/48000 (40.00%)]\tLoss: 0.099701\n",
      "Train Epoch: 7 [38400/48000 (80.00%)]\tLoss: 0.098633\n",
      "\n",
      "Training set: Accuracy: 47012/48000 (97.94%)\n",
      "Validation set: Accuracy: 11767/12000 (98.06%)\n",
      "\n",
      "Train Epoch: 8 [0/48000 (0.00%)]\tLoss: 0.030854\n",
      "Train Epoch: 8 [19200/48000 (40.00%)]\tLoss: 0.051010\n",
      "Train Epoch: 8 [38400/48000 (80.00%)]\tLoss: 0.041234\n",
      "\n",
      "Training set: Accuracy: 47143/48000 (98.21%)\n",
      "Validation set: Accuracy: 11718/12000 (97.65%)\n",
      "\n",
      "Train Epoch: 9 [0/48000 (0.00%)]\tLoss: 0.026733\n",
      "Train Epoch: 9 [19200/48000 (40.00%)]\tLoss: 0.020673\n",
      "Train Epoch: 9 [38400/48000 (80.00%)]\tLoss: 0.038273\n",
      "\n",
      "Training set: Accuracy: 47214/48000 (98.36%)\n",
      "Validation set: Accuracy: 11768/12000 (98.07%)\n",
      "\n",
      "Train Epoch: 10 [0/48000 (0.00%)]\tLoss: 0.030899\n",
      "Train Epoch: 10 [19200/48000 (40.00%)]\tLoss: 0.050425\n",
      "Train Epoch: 10 [38400/48000 (80.00%)]\tLoss: 0.128146\n",
      "\n",
      "Training set: Accuracy: 47289/48000 (98.52%)\n",
      "Validation set: Accuracy: 11798/12000 (98.32%)\n",
      "\n",
      "Train Epoch: 11 [0/48000 (0.00%)]\tLoss: 0.061716\n",
      "Train Epoch: 11 [19200/48000 (40.00%)]\tLoss: 0.009675\n",
      "Train Epoch: 11 [38400/48000 (80.00%)]\tLoss: 0.077935\n",
      "\n",
      "Training set: Accuracy: 47356/48000 (98.66%)\n",
      "Validation set: Accuracy: 11812/12000 (98.43%)\n",
      "\n",
      "Train Epoch: 12 [0/48000 (0.00%)]\tLoss: 0.074320\n",
      "Train Epoch: 12 [19200/48000 (40.00%)]\tLoss: 0.110331\n",
      "Train Epoch: 12 [38400/48000 (80.00%)]\tLoss: 0.019813\n",
      "\n",
      "Training set: Accuracy: 47410/48000 (98.77%)\n",
      "Validation set: Accuracy: 11807/12000 (98.39%)\n",
      "\n",
      "Train Epoch: 13 [0/48000 (0.00%)]\tLoss: 0.032302\n",
      "Train Epoch: 13 [19200/48000 (40.00%)]\tLoss: 0.005267\n",
      "Train Epoch: 13 [38400/48000 (80.00%)]\tLoss: 0.023265\n",
      "\n",
      "Training set: Accuracy: 47466/48000 (98.89%)\n",
      "Validation set: Accuracy: 11795/12000 (98.29%)\n",
      "\n",
      "Train Epoch: 14 [0/48000 (0.00%)]\tLoss: 0.013602\n",
      "Train Epoch: 14 [19200/48000 (40.00%)]\tLoss: 0.047994\n",
      "Train Epoch: 14 [38400/48000 (80.00%)]\tLoss: 0.102548\n",
      "\n",
      "Training set: Accuracy: 47495/48000 (98.95%)\n",
      "Validation set: Accuracy: 11814/12000 (98.45%)\n",
      "\n",
      "Test set: Accuracy: 9845/10000 (98.45%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_1().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64815daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/48000 (0.00%)]\tLoss: 2.304882\n",
      "Train Epoch: 0 [19200/48000 (40.00%)]\tLoss: 0.229798\n",
      "Train Epoch: 0 [38400/48000 (80.00%)]\tLoss: 0.080648\n",
      "\n",
      "Training set: Accuracy: 43948/48000 (91.56%)\n",
      "Validation set: Accuracy: 11612/12000 (96.77%)\n",
      "\n",
      "Train Epoch: 1 [0/48000 (0.00%)]\tLoss: 0.125944\n",
      "Train Epoch: 1 [19200/48000 (40.00%)]\tLoss: 0.029265\n",
      "Train Epoch: 1 [38400/48000 (80.00%)]\tLoss: 0.076984\n",
      "\n",
      "Training set: Accuracy: 46758/48000 (97.41%)\n",
      "Validation set: Accuracy: 11712/12000 (97.60%)\n",
      "\n",
      "Train Epoch: 2 [0/48000 (0.00%)]\tLoss: 0.028703\n",
      "Train Epoch: 2 [19200/48000 (40.00%)]\tLoss: 0.021141\n",
      "Train Epoch: 2 [38400/48000 (80.00%)]\tLoss: 0.053536\n",
      "\n",
      "Training set: Accuracy: 47085/48000 (98.09%)\n",
      "Validation set: Accuracy: 11754/12000 (97.95%)\n",
      "\n",
      "Train Epoch: 3 [0/48000 (0.00%)]\tLoss: 0.018225\n",
      "Train Epoch: 3 [19200/48000 (40.00%)]\tLoss: 0.132950\n",
      "Train Epoch: 3 [38400/48000 (80.00%)]\tLoss: 0.009621\n",
      "\n",
      "Training set: Accuracy: 47274/48000 (98.49%)\n",
      "Validation set: Accuracy: 11801/12000 (98.34%)\n",
      "\n",
      "Train Epoch: 4 [0/48000 (0.00%)]\tLoss: 0.004279\n",
      "Train Epoch: 4 [19200/48000 (40.00%)]\tLoss: 0.053356\n",
      "Train Epoch: 4 [38400/48000 (80.00%)]\tLoss: 0.018620\n",
      "\n",
      "Training set: Accuracy: 47381/48000 (98.71%)\n",
      "Validation set: Accuracy: 11792/12000 (98.27%)\n",
      "\n",
      "Train Epoch: 5 [0/48000 (0.00%)]\tLoss: 0.006035\n",
      "Train Epoch: 5 [19200/48000 (40.00%)]\tLoss: 0.116516\n",
      "Train Epoch: 5 [38400/48000 (80.00%)]\tLoss: 0.018442\n",
      "\n",
      "Training set: Accuracy: 47481/48000 (98.92%)\n",
      "Validation set: Accuracy: 11844/12000 (98.70%)\n",
      "\n",
      "Train Epoch: 6 [0/48000 (0.00%)]\tLoss: 0.016396\n",
      "Train Epoch: 6 [19200/48000 (40.00%)]\tLoss: 0.005826\n",
      "Train Epoch: 6 [38400/48000 (80.00%)]\tLoss: 0.096923\n",
      "\n",
      "Training set: Accuracy: 47579/48000 (99.12%)\n",
      "Validation set: Accuracy: 11814/12000 (98.45%)\n",
      "\n",
      "Train Epoch: 7 [0/48000 (0.00%)]\tLoss: 0.023899\n",
      "Train Epoch: 7 [19200/48000 (40.00%)]\tLoss: 0.053834\n",
      "Train Epoch: 7 [38400/48000 (80.00%)]\tLoss: 0.088017\n",
      "\n",
      "Training set: Accuracy: 47619/48000 (99.21%)\n",
      "Validation set: Accuracy: 11837/12000 (98.64%)\n",
      "\n",
      "Train Epoch: 8 [0/48000 (0.00%)]\tLoss: 0.060438\n",
      "Train Epoch: 8 [19200/48000 (40.00%)]\tLoss: 0.082700\n",
      "Train Epoch: 8 [38400/48000 (80.00%)]\tLoss: 0.003380\n",
      "\n",
      "Training set: Accuracy: 47653/48000 (99.28%)\n",
      "Validation set: Accuracy: 11862/12000 (98.85%)\n",
      "\n",
      "Train Epoch: 9 [0/48000 (0.00%)]\tLoss: 0.000232\n",
      "Train Epoch: 9 [19200/48000 (40.00%)]\tLoss: 0.000905\n",
      "Train Epoch: 9 [38400/48000 (80.00%)]\tLoss: 0.003436\n",
      "\n",
      "Training set: Accuracy: 47696/48000 (99.37%)\n",
      "Validation set: Accuracy: 11860/12000 (98.83%)\n",
      "\n",
      "Train Epoch: 10 [0/48000 (0.00%)]\tLoss: 0.009199\n",
      "Train Epoch: 10 [19200/48000 (40.00%)]\tLoss: 0.001120\n",
      "Train Epoch: 10 [38400/48000 (80.00%)]\tLoss: 0.014643\n",
      "\n",
      "Training set: Accuracy: 47720/48000 (99.42%)\n",
      "Validation set: Accuracy: 11860/12000 (98.83%)\n",
      "\n",
      "Train Epoch: 11 [0/48000 (0.00%)]\tLoss: 0.001533\n",
      "Train Epoch: 11 [19200/48000 (40.00%)]\tLoss: 0.007047\n",
      "Train Epoch: 11 [38400/48000 (80.00%)]\tLoss: 0.002425\n",
      "\n",
      "Training set: Accuracy: 47743/48000 (99.46%)\n",
      "Validation set: Accuracy: 11877/12000 (98.97%)\n",
      "\n",
      "Train Epoch: 12 [0/48000 (0.00%)]\tLoss: 0.016308\n",
      "Train Epoch: 12 [19200/48000 (40.00%)]\tLoss: 0.001130\n",
      "Train Epoch: 12 [38400/48000 (80.00%)]\tLoss: 0.002056\n",
      "\n",
      "Training set: Accuracy: 47817/48000 (99.62%)\n",
      "Validation set: Accuracy: 11870/12000 (98.92%)\n",
      "\n",
      "Train Epoch: 13 [0/48000 (0.00%)]\tLoss: 0.001558\n",
      "Train Epoch: 13 [19200/48000 (40.00%)]\tLoss: 0.009350\n",
      "Train Epoch: 13 [38400/48000 (80.00%)]\tLoss: 0.030670\n",
      "\n",
      "Training set: Accuracy: 47803/48000 (99.59%)\n",
      "Validation set: Accuracy: 11852/12000 (98.77%)\n",
      "\n",
      "Train Epoch: 14 [0/48000 (0.00%)]\tLoss: 0.008182\n",
      "Train Epoch: 14 [19200/48000 (40.00%)]\tLoss: 0.000491\n",
      "Train Epoch: 14 [38400/48000 (80.00%)]\tLoss: 0.000918\n",
      "\n",
      "Training set: Accuracy: 47807/48000 (99.60%)\n",
      "Validation set: Accuracy: 11876/12000 (98.97%)\n",
      "\n",
      "Test set: Accuracy: 9907/10000 (99.07%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_2().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b1471",
   "metadata": {},
   "source": [
    "## 9. 두모델의 성능을 비교하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8156f",
   "metadata": {},
   "source": [
    "정답) 두 모델 모두 높은 정확도를 가지며 빠르게 학습이 진행된다. 하지만 최종적인 결과를 봤을 때, sigmoid를 사용한 모델은 98% 정도의 정확도에 그쳤지만, ReLU를 사용한 모델은 조금 더 높은 수치인 99%를 근소하게 넘는 정확도를 보이는 것으로 보아 ReLU를 사용한 모델이 더 성능이 좋다고 할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
